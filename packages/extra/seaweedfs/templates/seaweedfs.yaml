{{- /* Preflight checks for Helm template */ -}}
{{- if not (has .Values.topology (list "Simple" "MultiZone" "Client")) }}
{{-   fail "Invalid value for .Values.topology. Must be one of 'Simple', 'MultiZone' or 'Client'." }}
{{- end }}
{{- if and (eq .Values.topology "Client") (not .Values.filer.grpcHost) }}
{{-   fail "When topology is 'Client', .Values.filer.grpcHost must be set to a valid remote filer GRPC service endpoint." }}
{{- end }}
{{- if lt (int .Values.replicationFactor) 1 }}
{{-   fail "Invalid value for .Values.replicationFactor. Must be at least 1." }}
{{- end }}
{{- if eq .Values.topology "MultiZone" }}
{{-   if (eq (len .Values.volume.zones) 0) }}
{{-     fail "Zones must be defined for MultiZone topology." }}
{{-   end }}
{{-   if and (hasKey .Values.volume "zones") (gt (int .Values.replicationFactor) (len .Values.volume.zones)) }}
{{-     fail "replicationFactor must be less than or equal to the number of zones defined in .Values.volume.zones." }}
{{-   end }}
{{- end }}
{{- if and (eq .Values.topology "Client") (gt (len .Values.volume.pools) 0) }}
{{-   fail "volume.pools is not supported with Client topology." }}
{{- end }}
{{- if and (eq .Values.topology "MultiZone") (gt (len .Values.volume.pools) 0) }}
{{-   fail "volume.pools is not supported with MultiZone topology. Use volume.zones[name].pools instead." }}
{{- end }}
{{- if and .Values.volume.diskType (not (regexMatch "^[a-z0-9]+$" .Values.volume.diskType)) }}
{{-   fail (printf "volume.diskType must be lowercase alphanumeric (got: %s)." .Values.volume.diskType) }}
{{- end }}

{{- /* Collect and validate all pools from volume.pools and zones[].pools */ -}}
{{- $allPools := dict }}
{{- range $poolName, $pool := .Values.volume.pools }}
{{-   if not (regexMatch "^[a-z0-9]([a-z0-9-]*[a-z0-9])?$" $poolName) }}
{{-     fail (printf "volume.pools key '%s' must be a valid DNS label (lowercase alphanumeric and hyphens, no dots)." $poolName) }}
{{-   end }}
{{-   if or (hasSuffix "-lock" $poolName) (hasSuffix "-readonly" $poolName) }}
{{-     fail (printf "volume.pools key '%s' must not end with '-lock' or '-readonly' (reserved suffixes for COSI resources)." $poolName) }}
{{-   end }}
{{-   if not $pool.diskType }}
{{-     fail (printf "volume.pools.%s.diskType is required." $poolName) }}
{{-   end }}
{{-   if not (regexMatch "^[a-z0-9]+$" $pool.diskType) }}
{{-     fail (printf "volume.pools.%s.diskType must be lowercase alphanumeric (got: %s)." $poolName $pool.diskType) }}
{{-   end }}
{{-   if and $.Values.volume.diskType (eq $pool.diskType $.Values.volume.diskType) }}
{{-     fail (printf "volume.pools.%s.diskType '%s' must differ from volume.diskType." $poolName $pool.diskType) }}
{{-   end }}
{{-   $_ := set $allPools $poolName $pool.diskType }}
{{- end }}
{{- if eq .Values.topology "MultiZone" }}
{{-   range $zoneName, $zone := .Values.volume.zones }}
{{-     range $poolName, $pool := (dig "pools" dict $zone) }}
{{-       if not (regexMatch "^[a-z0-9]([a-z0-9-]*[a-z0-9])?$" $poolName) }}
{{-         fail (printf "volume.zones.%s.pools key '%s' must be a valid DNS label." $zoneName $poolName) }}
{{-       end }}
{{-       if or (hasSuffix "-lock" $poolName) (hasSuffix "-readonly" $poolName) }}
{{-         fail (printf "volume.zones.%s.pools key '%s' must not end with '-lock' or '-readonly' (reserved suffixes for COSI resources)." $zoneName $poolName) }}
{{-       end }}
{{-       if not $pool.diskType }}
{{-         fail (printf "volume.zones.%s.pools.%s.diskType is required." $zoneName $poolName) }}
{{-       end }}
{{-       if not (regexMatch "^[a-z0-9]+$" $pool.diskType) }}
{{-         fail (printf "volume.zones.%s.pools.%s.diskType must be lowercase alphanumeric (got: %s)." $zoneName $poolName $pool.diskType) }}
{{-       end }}
{{-       if and $.Values.volume.diskType (eq $pool.diskType $.Values.volume.diskType) }}
{{-         fail (printf "volume.zones.%s.pools.%s.diskType '%s' must differ from volume.diskType." $zoneName $poolName $pool.diskType) }}
{{-       end }}
{{-       if and (hasKey $allPools $poolName) (ne (get $allPools $poolName) $pool.diskType) }}
{{-         fail (printf "Pool '%s' has inconsistent diskType across zones (expected '%s', got '%s' in zone '%s')." $poolName (get $allPools $poolName) $pool.diskType $zoneName) }}
{{-       end }}
{{-       $_ := set $allPools $poolName $pool.diskType }}
{{-       $composedName := printf "%s-%s" $zoneName $poolName }}
{{-       if hasKey $.Values.volume.zones $composedName }}
{{-         fail (printf "Composed volume name '%s' (from zone '%s' and pool '%s') collides with an existing zone name." $composedName $zoneName $poolName) }}
{{-       end }}
{{-     end }}
{{-   end }}
{{- end }}

{{- $detectedTopology := "Unknown" }}
{{- $configMap := lookup "v1" "ConfigMap" .Release.Namespace (printf "%s-deployed-topology" .Release.Name) }}
{{- if $configMap }}
{{-   $detectedTopology = dig "data" "topology" "Unknown" $configMap }}
{{- else }}
{{-   if lookup "v1" "PersistentVolumeClaim" .Release.Namespace (printf "data1-%s-volume-0" .Release.Name) }}
{{-     $detectedTopology = "Simple" }}
{{-   else if lookup "apps/v1" "StatefulSet" .Release.Namespace (printf "%s-master" .Release.Name) }}
{{-     $detectedTopology = "MultiZone" }}
{{-   end }}
{{- end }}

{{- if not (has $detectedTopology (list .Values.topology "Unknown")) }}
{{-   fail (printf "Not allowed to switch between topologies after the first deployment: %s" $detectedTopology) }}
{{- end }}

{{- if not (eq .Values.topology "Client") }}
{{- $ingress := .Values._namespace.ingress }}
{{- $host := .Values._namespace.host }}
{{- $solver := (index .Values._cluster "solver") | default "http01" }}
{{- $clusterIssuer := (index .Values._cluster "issuer-name") | default "letsencrypt-prod" }}
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: {{ .Release.Name }}-system
  labels:
    sharding.fluxcd.io/key: tenants
spec:
  chartRef:
    kind: ExternalArtifact
    name: cozystack-seaweedfs-application-default-seaweedfs-system
    namespace: cozy-system
  interval: 5m
  timeout: 10m
  install:
    remediation:
      retries: -1
  upgrade:
    force: true
    remediation:
      retries: -1
  valuesFrom:
  - kind: Secret
    name: cozystack-values
  values:
    global:
      serviceAccountName: "{{ .Release.Namespace }}-seaweedfs"
    db:
      replicas: {{ .Values.db.replicas }}
      resources: {{- include "cozy-lib.resources.defaultingSanitize" (list .Values.db.resourcesPreset .Values.db.resources $) | nindent 8 }}
      size: {{ .Values.db.size }}
      {{- with .Values.db.storageClass }}
      storageClass: {{ . }}
      {{- end }}
    seaweedfs:
      master:
        {{ if eq .Values.topology "Simple" }}
        defaultReplicaPlacement: "00{{ sub .Values.replicationFactor 1 }}"
        {{- else if eq .Values.topology "MultiZone" }}
        defaultReplicaPlacement: "{{ sub .Values.replicationFactor 1 }}00"
        {{- end }}
        replicas: {{ .Values.master.replicas }}
        resources: {{- include "cozy-lib.resources.defaultingSanitize" (list .Values.master.resourcesPreset .Values.master.resources $) | nindent 10 }}
      volume:
        {{ if eq .Values.topology "MultiZone" }}
        enabled: false
        {{- end }}
        replicas: {{ .Values.volume.replicas }}
        resources: {{- include "cozy-lib.resources.defaultingSanitize" (list .Values.volume.resourcesPreset .Values.volume.resources $) | nindent 10 }}
        dataDirs:
        - name: data1
          type: "persistentVolumeClaim"
          size: "{{ .Values.volume.size }}"
          {{- with .Values.volume.storageClass }}
          storageClass: {{ . }}
          {{- end }}
          maxVolumes: 0
        {{- if .Values.volume.diskType }}
        extraArgs:
        - "-disk={{ .Values.volume.diskType }}"
        {{- end }}
      {{- if or (and (eq .Values.topology "Simple") (gt (len .Values.volume.pools) 0)) (eq .Values.topology "MultiZone") }}
      volumes:
        {{- if eq .Values.topology "Simple" }}
        {{- range $poolName, $pool := .Values.volume.pools }}
        {{ $poolName }}:
          replicas: {{ ternary $pool.replicas $.Values.volume.replicas (hasKey $pool "replicas") }}
          resources: {{- include "cozy-lib.resources.defaultingSanitize" (list ($pool.resourcesPreset | default $.Values.volume.resourcesPreset) (default dict $pool.resources) $) | nindent 12 }}
          dataDirs:
          - name: data1
            type: "persistentVolumeClaim"
            size: "{{ $pool.size | default $.Values.volume.size }}"
            {{- with ($pool.storageClass | default $.Values.volume.storageClass) }}
            storageClass: "{{ . }}"
            {{- end }}
            maxVolumes: 0
          extraArgs:
          - "-disk={{ $pool.diskType }}"
        {{- end }}
        {{- else if eq .Values.topology "MultiZone" }}
        {{- range $zoneName, $zone := .Values.volume.zones }}
        {{ $zoneName }}:
          replicas: {{ ternary $zone.replicas $.Values.volume.replicas (hasKey $zone "replicas") }}
          resources: {{- include "cozy-lib.resources.defaultingSanitize" (list $.Values.volume.resourcesPreset $.Values.volume.resources $) | nindent 12 }}
          dataDirs:
          - name: data1
            type: "persistentVolumeClaim"
            size: "{{ $zone.size | default $.Values.volume.size }}"
            {{- with ($zone.storageClass | default $.Values.volume.storageClass) }}
            storageClass: "{{ . }}"
            {{- end }}
            maxVolumes: 0
          nodeSelector: |
            {{- with $zone.nodeSelector }}
{{ . | indent 12 }}
            {{- else }}
            topology.kubernetes.io/zone: {{ $zoneName }}
            {{- end }}
          dataCenter: {{ $zone.dataCenter | default $zoneName }}
          {{- if $.Values.volume.diskType }}
          extraArgs:
          - "-disk={{ $.Values.volume.diskType }}"
          {{- end }}
        {{- end }}
        {{- range $zoneName, $zone := .Values.volume.zones }}
        {{- range $poolName, $pool := (dig "pools" dict $zone) }}
        {{ $zoneName }}-{{ $poolName }}:
          replicas: {{ ternary $pool.replicas (ternary $zone.replicas $.Values.volume.replicas (hasKey $zone "replicas")) (hasKey $pool "replicas") }}
          resources: {{- include "cozy-lib.resources.defaultingSanitize" (list ($pool.resourcesPreset | default $.Values.volume.resourcesPreset) (default dict $pool.resources) $) | nindent 12 }}
          dataDirs:
          - name: data1
            type: "persistentVolumeClaim"
            size: "{{ $pool.size | default $zone.size | default $.Values.volume.size }}"
            {{- with ($pool.storageClass | default $zone.storageClass | default $.Values.volume.storageClass) }}
            storageClass: "{{ . }}"
            {{- end }}
            maxVolumes: 0
          nodeSelector: |
            {{- with $zone.nodeSelector }}
{{ . | indent 12 }}
            {{- else }}
            topology.kubernetes.io/zone: {{ $zoneName }}
            {{- end }}
          dataCenter: {{ $zone.dataCenter | default $zoneName }}
          extraArgs:
          - "-disk={{ $pool.diskType }}"
        {{- end }}
        {{- end }}
        {{- end }}
      {{- end }}
      filer:
        {{ if eq .Values.topology "Simple" }}
        defaultReplicaPlacement: "00{{ sub .Values.replicationFactor 1 }}"
        {{- else if eq .Values.topology "MultiZone" }}
        defaultReplicaPlacement: "{{ sub .Values.replicationFactor 1 }}00"
        {{- end }}
        s3:
          domainName: {{ .Values.host | default (printf "s3.%s" $host) }}
        resources: {{- include "cozy-lib.resources.defaultingSanitize" (list .Values.filer.resourcesPreset .Values.filer.resources $) | nindent 10 }}
      s3:
        ingress:
          className: {{ $ingress }}
          host: {{ .Values.host | default (printf "s3.%s" $host) }}
          annotations:
            nginx.ingress.kubernetes.io/proxy-body-size: "0"
            nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
            {{- if eq $solver "http01" }}
            acme.cert-manager.io/http01-ingress-class: {{ $ingress }}
            {{- end }}
            cert-manager.io/cluster-issuer: {{ $clusterIssuer }}
          tls:
            - hosts:
              - {{ .Values.host | default (printf "s3.%s" $host) }}
              secretName: {{ .Release.Name }}-s3-ingress-tls
        resources: {{- include "cozy-lib.resources.defaultingSanitize" (list .Values.s3.resourcesPreset .Values.s3.resources $) | nindent 10 }}
      cosi:
        driverName: "{{ .Release.Namespace }}.seaweedfs.objectstorage.k8s.io"
        bucketClassName: "{{ .Release.Namespace }}"
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "500m"
            memory: "512Mi"
---
apiVersion: cozystack.io/v1alpha1
kind: WorkloadMonitor
metadata:
  name: {{ $.Release.Name }}-master
spec:
  replicas: {{ .Values.master.replicas }}
  minReplicas: {{ div .Values.master.replicas 2 | add1 }}
  kind: seaweedfs
  type: master
  selector:
    app.kubernetes.io/component: master
    app.kubernetes.io/name: seaweedfs
  version: {{ $.Chart.Version }}
---
apiVersion: cozystack.io/v1alpha1
kind: WorkloadMonitor
metadata:
  name: {{ $.Release.Name }}-filer
spec:
  replicas: {{ .Values.filer.replicas }}
  minReplicas: 1
  kind: seaweedfs
  type: filer
  selector:
    app.kubernetes.io/component: filer
    app.kubernetes.io/name: seaweedfs
  version: {{ $.Chart.Version }}

{{ if eq .Values.topology "Simple" }}
---
apiVersion: cozystack.io/v1alpha1
kind: WorkloadMonitor
metadata:
  name: {{ $.Release.Name }}-volume
spec:
  replicas: {{ .Values.volume.replicas }}
  minReplicas: 1
  kind: seaweedfs
  type: volume
  selector:
    app.kubernetes.io/component: volume
    app.kubernetes.io/name: seaweedfs
  version: {{ $.Chart.Version }}
{{- range $poolName, $pool := .Values.volume.pools }}
---
apiVersion: cozystack.io/v1alpha1
kind: WorkloadMonitor
metadata:
  name: {{ $.Release.Name }}-volume-{{ $poolName }}
spec:
  replicas: {{ ternary $pool.replicas $.Values.volume.replicas (hasKey $pool "replicas") }}
  minReplicas: 1
  kind: seaweedfs
  type: volume
  selector:
    app.kubernetes.io/component: volume-{{ $poolName }}
    app.kubernetes.io/name: seaweedfs
  version: {{ $.Chart.Version }}
{{- end }}
{{- else if eq .Values.topology "MultiZone" }}
{{- range $zoneName, $zoneSpec := .Values.volume.zones }}
---
apiVersion: cozystack.io/v1alpha1
kind: WorkloadMonitor
metadata:
  name: {{ $.Release.Name }}-volume-{{ $zoneName }}
spec:
  replicas: {{ ternary $zoneSpec.replicas $.Values.volume.replicas (hasKey $zoneSpec "replicas") }}
  minReplicas: 1
  kind: seaweedfs
  type: volume
  selector:
    app.kubernetes.io/component: volume-{{ $zoneName }}
    app.kubernetes.io/name: seaweedfs
  version: {{ $.Chart.Version }}
{{- range $poolName, $pool := (dig "pools" dict $zoneSpec) }}
---
apiVersion: cozystack.io/v1alpha1
kind: WorkloadMonitor
metadata:
  name: {{ $.Release.Name }}-volume-{{ $zoneName }}-{{ $poolName }}
spec:
  replicas: {{ ternary $pool.replicas (ternary $zoneSpec.replicas $.Values.volume.replicas (hasKey $zoneSpec "replicas")) (hasKey $pool "replicas") }}
  minReplicas: 1
  kind: seaweedfs
  type: volume
  selector:
    app.kubernetes.io/component: volume-{{ $zoneName }}-{{ $poolName }}
    app.kubernetes.io/name: seaweedfs
  version: {{ $.Chart.Version }}
{{- end }}
{{- end }}
{{- end }}
---
apiVersion: cozystack.io/v1alpha1
kind: WorkloadMonitor
metadata:
  name: {{ $.Release.Name }}-db
spec:
  replicas: {{ .Values.db.replicas }}
  minReplicas: 1
  kind: seaweedfs
  type: postgres
  selector:
    cnpg.io/cluster: seaweedfs-db
    cnpg.io/podRole: instance
  version: {{ $.Chart.Version }}
---
apiVersion: cozystack.io/v1alpha1
kind: WorkloadMonitor
metadata:
  name: {{ $.Release.Name }}-s3
spec:
  replicas: {{ .Values.s3.replicas }}
  minReplicas: 1
  kind: seaweedfs
  type: s3
  selector:
    app.kubernetes.io/component: s3
    app.kubernetes.io/name: seaweedfs
  version: {{ $.Chart.Version }}
{{- end }}
